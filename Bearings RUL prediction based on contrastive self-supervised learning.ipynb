{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch  # GPU support\n\ndef load_ieee_phm_vibration_data(directory, use_gpu=True):\n    \"\"\"\n    Loads vibration signal data from the IEEE PHM 2012 Bearing Dataset with correct separator.\n\n    Parameters:\n        directory (str): Path to the dataset directory in Kaggle.\n        use_gpu (bool): Whether to load data onto GPU.\n\n    Returns:\n        data_dict (dict): Dictionary where keys are file paths and values are vibration signal tensors.\n    \"\"\"\n    data_dict = {}\n\n    # Check if GPU is available\n    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n\n    # Walk through all subdirectories (e.g., Bearing1_1, Bearing1_2, etc.)\n    for bearing_folder in sorted(os.listdir(directory)):\n        bearing_path = os.path.join(directory, bearing_folder)\n        if os.path.isdir(bearing_path):  # Ensure it's a directory\n            print(f\"\\nğŸ“‚ Processing Bearing Folder: {bearing_folder}\")\n            data_dict[bearing_folder] = []\n            \n            # Read all CSV files inside each bearing folder\n            for file_name in sorted(os.listdir(bearing_path)):\n                if file_name.startswith(\"acc\") and file_name.endswith(\".csv\"):  # Load only vibration files\n                    file_path = os.path.join(bearing_path, file_name)\n                    \n                    try:\n                        # print(f\"ğŸ”„ Loading vibration file: {file_name}\")\n\n                        # Load CSV file using COMMA separator\n                        df = pd.read_csv(file_path, sep=\",\", header=None, dtype=str, engine=\"python\")\n\n                        # print(f\"\\nğŸ”¹ Raw CSV Data from {file_name} (First 5 rows):\\n{df.head()}\\n\")\n\n                        # Ensure we select only numeric acceleration columns\n                        # print(f\"ğŸ” CSV Shape Before Processing: {df.shape}\")\n\n                        # Drop timestamp columns (Assuming first 4 columns are time-related)\n                        df = df.iloc[:, -2:]  # Keep only the last 2 columns (Horizontal & Vertical acceleration)\n\n                        # Convert to numeric values\n                        df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n\n                        # print(f\"ğŸ”¹ Processed CSV Data (First 5 rows after numeric conversion):\\n{df.head()}\\n\")\n\n                        if df.shape[0] == 0 or df.shape[1] != 2:\n                            print(f\"âš ï¸ Skipping {file_name} - No valid numeric data found.\")\n                            continue\n\n                        # Convert to numpy array and flatten\n                        signal_data = df.values.flatten()\n                        # print(f\"âœ… Loaded {file_name}: Shape {signal_data.shape}\")\n\n                        # Convert to PyTorch Tensor and move to GPU if available\n                        signal_tensor = torch.tensor(signal_data, dtype=torch.float32).to(device)\n\n                        # Store in dictionary (append to list)\n                        data_dict[bearing_folder].append(signal_tensor)\n\n                    except Exception as e:\n                        print(f\"âŒ Error loading {file_path}: {e}\")\n                        continue\n\n    return data_dict, device\n\n# Set the dataset directory (Update this path based on your Kaggle dataset location)\ndataset_directory = \"/kaggle/input/ieee-phm-2012-data-challenge/ieee-phm-2012-data-challenge-dataset-master/Learning_set\"\n\n# Load the dataset (GPU enabled) with corrected separator\nbearing_data, device = load_ieee_phm_vibration_data(dataset_directory, use_gpu=True)\n\n# Display available bearings and sample data shape\nprint(f\"\\nğŸš€ Using device: {device}\")\nprint(\"âœ… Loaded Bearings:\", list(bearing_data.keys())[:5])\n\n# Check if any valid data exists\nfor bearing, signals in bearing_data.items():\n    if len(signals) > 0:\n        print(f\"ğŸ“Š {bearing} First CSV Shape: {signals[0].shape}\")\n    else:\n        print(f\"âš ï¸ {bearing} contains NO valid data!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T11:54:13.744066Z","iopub.execute_input":"2025-02-02T11:54:13.744315Z","iopub.status.idle":"2025-02-02T11:56:24.660356Z","shell.execute_reply.started":"2025-02-02T11:54:13.744291Z","shell.execute_reply":"2025-02-02T11:56:24.659271Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“‚ Processing Bearing Folder: Bearing1_1\n\nğŸ“‚ Processing Bearing Folder: Bearing1_2\n\nğŸ“‚ Processing Bearing Folder: Bearing2_1\n\nğŸ“‚ Processing Bearing Folder: Bearing2_2\n\nğŸ“‚ Processing Bearing Folder: Bearing3_1\n\nğŸ“‚ Processing Bearing Folder: Bearing3_2\n\nğŸš€ Using device: cuda\nâœ… Loaded Bearings: ['Bearing1_1', 'Bearing1_2', 'Bearing2_1', 'Bearing2_2', 'Bearing3_1']\nğŸ“Š Bearing1_1 First CSV Shape: torch.Size([5120])\nğŸ“Š Bearing1_2 First CSV Shape: torch.Size([5120])\nğŸ“Š Bearing2_1 First CSV Shape: torch.Size([5120])\nğŸ“Š Bearing2_2 First CSV Shape: torch.Size([5120])\nğŸ“Š Bearing3_1 First CSV Shape: torch.Size([5120])\nğŸ“Š Bearing3_2 First CSV Shape: torch.Size([5120])\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pywt\nimport torch\nimport numpy as np\n\ndef apply_wavelet_transform_paper(data_dict, wavelet=\"db8\", level=1, trunc_length=1280):\n    \"\"\"\n    Applies Discrete Wavelet Transform (DWT) using 'db8' at level 1 and ensures correct truncation as per the paper.\n\n    Parameters:\n        data_dict (dict): Dictionary containing vibration signal tensors.\n        wavelet (str): Type of wavelet to use (default: \"db8\").\n        level (int): Decomposition level (fixed at 1 based on the paper).\n        trunc_length (int): Fixed length to truncate the coefficients to (default: 1280).\n\n    Returns:\n        wavelet_dict (dict): Dictionary with transformed and truncated wavelet coefficients.\n    \"\"\"\n    wavelet_dict = {}\n\n    for bearing, signals in data_dict.items():\n        print(f\"\\nğŸ”„ Processing Bearing: {bearing}\")\n        wavelet_dict[bearing] = []\n\n        for signal_tensor in signals:\n            # Convert PyTorch tensor to NumPy for processing\n            signal_np = signal_tensor.cpu().numpy()\n\n            # **Step 1: Apply Discrete Wavelet Transform (DWT) at level 1**\n            coeffs = pywt.wavedec(signal_np, wavelet, level=level)\n\n            # **Step 2: Extract Approximate & Detail Coefficients**\n            approx_coeffs = coeffs[0]  # Approximate Coefficients (Low-Frequency)\n            detail_coeffs = coeffs[1]  # First-Level Detail Coefficients (High-Frequency)\n\n            # **Step 3: Truncate half of each spectrum**\n            trunc_approx = approx_coeffs[:trunc_length]\n            trunc_detail = detail_coeffs[:trunc_length]\n\n            # **Step 4: Stack into (2, 1280) format for CNN input**\n            wavelet_processed = torch.tensor([trunc_approx, trunc_detail], dtype=torch.float32, device=signal_tensor.device)\n\n            # Store processed wavelet data\n            wavelet_dict[bearing].append(wavelet_processed)\n\n            # print(f\"âœ… {bearing}: Level {level}, Original Shape {signal_np.shape} â†’ Truncated Shape {wavelet_processed.shape}\")\n\n    return wavelet_dict\n\n# Apply Wavelet Transform as per the paper with level=1\nwavelet_data_paper = apply_wavelet_transform_paper(bearing_data, wavelet=\"db8\", level=1, trunc_length=1280)\n\n# ğŸ”¹ Print final shape for verification\nprint(\"\\nğŸš€ Final Verification of Shapes:\")\nfor bearing, signals in wavelet_data_paper.items():\n    if len(signals) > 0:\n        print(f\"ğŸ“Š {bearing} Processed Shape: {signals[0].shape}\")\n    else:\n        print(f\"âš ï¸ {bearing} contains NO processed wavelet data!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T11:56:24.661467Z","iopub.execute_input":"2025-02-02T11:56:24.661807Z","iopub.status.idle":"2025-02-02T11:56:29.334669Z","shell.execute_reply.started":"2025-02-02T11:56:24.661773Z","shell.execute_reply":"2025-02-02T11:56:29.333929Z"}},"outputs":[{"name":"stdout","text":"\nğŸ”„ Processing Bearing: Bearing1_1\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-2-d6a8dc43a723>:40: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  wavelet_processed = torch.tensor([trunc_approx, trunc_detail], dtype=torch.float32, device=signal_tensor.device)\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ”„ Processing Bearing: Bearing1_2\n\nğŸ”„ Processing Bearing: Bearing2_1\n\nğŸ”„ Processing Bearing: Bearing2_2\n\nğŸ”„ Processing Bearing: Bearing3_1\n\nğŸ”„ Processing Bearing: Bearing3_2\n\nğŸš€ Final Verification of Shapes:\nğŸ“Š Bearing1_1 Processed Shape: torch.Size([2, 1280])\nğŸ“Š Bearing1_2 Processed Shape: torch.Size([2, 1280])\nğŸ“Š Bearing2_1 Processed Shape: torch.Size([2, 1280])\nğŸ“Š Bearing2_2 Processed Shape: torch.Size([2, 1280])\nğŸ“Š Bearing3_1 Processed Shape: torch.Size([2, 1280])\nğŸ“Š Bearing3_2 Processed Shape: torch.Size([2, 1280])\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\n\ndef sliding_window_segmentation_fixed(data_dict, window_size=12, step_size=1):\n    \"\"\"\n    Implements sliding window segmentation with separate positive and negative sample lists.\n    \n    Parameters:\n        data_dict (dict): Dictionary containing wavelet-transformed vibration signal tensors.\n        window_size (int): The size of each historical segment (default: 12).\n        step_size (int): The step size for moving the window (default: 1).\n\n    Returns:\n        positive_samples (dict): Dictionary containing positive-order segments.\n        negative_samples (dict): Dictionary containing reversed-order segments.\n    \"\"\"\n    positive_samples = {}\n    negative_samples = {}\n\n    for bearing, signals in data_dict.items():\n        print(f\"\\nğŸ”„ Processing Sliding Window Segmentation for: {bearing}\")\n        positive_samples[bearing] = []\n        negative_samples[bearing] = []\n\n        for signal_tensor in signals:\n            # Convert to NumPy and print original shape\n            sequence = signal_tensor.cpu().numpy()  # Expecting (2, 1280)\n            # print(f\"ğŸ“ Original Shape: {sequence.shape}\")  # Confirm it is (2, 1280)\n\n            seq_length = sequence.shape[1]  # Time axis = 1280\n\n            # **Step 1: Randomly Cut the First Two-Thirds of the Trajectory**\n            cut_length = int(2/3 * seq_length)  # First two-thirds\n            random_start = random.randint(0, cut_length - int(0.5 * cut_length))  # Random cut within first 2/3\n            truncated_sequence = sequence[:, random_start:random_start + int(0.5 * cut_length)]  # Shape (2, N)\n\n            # print(f\"âœ‚ï¸ Truncated Sequence Shape: {truncated_sequence.shape}\")  # Expecting (2, ~640)\n\n            # **Step 2: Apply Sliding Window Segmentation Over TIME Dimension**\n            num_segments = (truncated_sequence.shape[1] - window_size) // step_size + 1\n\n            for i in range(num_segments):\n                start_idx = i * step_size\n                end_idx = start_idx + window_size\n\n                # Extract the segment correctly over the TIME axis\n                segment = truncated_sequence[:, start_idx:end_idx]  # Expecting (2, 12)\n                # print(f\"ğŸªŸ Segment {i} Shape: {segment.shape}\")  # Should be (2, 12)\n\n                # **Save Positive Sample**\n                positive_samples[bearing].append(torch.tensor(segment, dtype=torch.float32, device=signal_tensor.device))\n\n                # **Create Negative Sample (Reversed Order in Time Axis, with Copy Fix)**\n                segment_reversed = np.flip(segment, axis=1).copy()  # Reverse time axis & make a copy\n                negative_samples[bearing].append(torch.tensor(segment_reversed, dtype=torch.float32, device=signal_tensor.device))\n\n            # print(f\"âœ… {bearing}: Generated {num_segments} Segments.\")\n\n    return positive_samples, negative_samples\n\n# Apply Fixed Sliding Window Segmentation\npositive_samples, negative_samples = sliding_window_segmentation_fixed(wavelet_data_paper, window_size=12, step_size=1)\n\n# ğŸ”¹ Print final verification\nprint(\"\\nğŸš€ Final Verification of Segmented Data:\")\nfor bearing in positive_samples.keys():\n    if len(positive_samples[bearing]) > 0:\n        print(f\"ğŸ“Š {bearing} First Positive Sample Shape: {positive_samples[bearing][0].shape}\")\n        print(f\"ğŸ“Š {bearing} First Negative Sample Shape: {negative_samples[bearing][0].shape}\")\n    else:\n        print(f\"âš ï¸ {bearing} contains NO segmented data!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T11:56:37.727677Z","iopub.execute_input":"2025-02-02T11:56:37.728015Z","iopub.status.idle":"2025-02-02T11:59:54.696922Z","shell.execute_reply.started":"2025-02-02T11:56:37.727987Z","shell.execute_reply":"2025-02-02T11:59:54.696069Z"}},"outputs":[{"name":"stdout","text":"\nğŸ”„ Processing Sliding Window Segmentation for: Bearing1_1\n\nğŸ”„ Processing Sliding Window Segmentation for: Bearing1_2\n\nğŸ”„ Processing Sliding Window Segmentation for: Bearing2_1\n\nğŸ”„ Processing Sliding Window Segmentation for: Bearing2_2\n\nğŸ”„ Processing Sliding Window Segmentation for: Bearing3_1\n\nğŸ”„ Processing Sliding Window Segmentation for: Bearing3_2\n\nğŸš€ Final Verification of Segmented Data:\nğŸ“Š Bearing1_1 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing1_1 First Negative Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing1_2 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing1_2 First Negative Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing2_1 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing2_1 First Negative Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing2_2 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing2_2 First Negative Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing3_1 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing3_1 First Negative Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing3_2 First Positive Sample Shape: torch.Size([2, 12])\nğŸ“Š Bearing3_2 First Negative Sample Shape: torch.Size([2, 12])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SiameseCNN(nn.Module):\n    def __init__(self):\n        super(SiameseCNN, self).__init__()\n\n        # 1D CNN to extract features from vibration signals\n        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=3, padding=1)  # Input: (batch, 2, 12)\n        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n        \n        # Global average pooling to reduce spatial dimensions\n        self.global_pool = nn.AdaptiveAvgPool1d(1)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(256, 128)\n        self.fc2 = nn.Linear(128, 64)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.global_pool(x).squeeze(-1)  # Shape: (batch, 256)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)  # Output: (batch, 64)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T12:00:13.368607Z","iopub.execute_input":"2025-02-02T12:00:13.368905Z","iopub.status.idle":"2025-02-02T12:00:13.375158Z","shell.execute_reply.started":"2025-02-02T12:00:13.368880Z","shell.execute_reply":"2025-02-02T12:00:13.374219Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, positive_features, negative_features):\n        # Compute Euclidean distance between feature vectors\n        distance = F.pairwise_distance(positive_features, negative_features, keepdim=True)\n        \n        # Loss encourages positive pairs to be close and negative pairs to be far apart\n        loss = torch.mean((1) * torch.pow(distance, 2) + (1 - 1) * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2))\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T12:00:17.933568Z","iopub.execute_input":"2025-02-02T12:00:17.933862Z","iopub.status.idle":"2025-02-02T12:00:17.939230Z","shell.execute_reply.started":"2025-02-02T12:00:17.933837Z","shell.execute_reply":"2025-02-02T12:00:17.938370Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import random\nimport torch\n\n# Define total number of pretext samples needed\nTARGET_PRETEXT_SAMPLES = 251520\n\ndef sample_pretext_data(positive_samples, negative_samples, target_size):\n    \"\"\"\n    Randomly selects 'target_size' samples from positive and negative datasets.\n\n    Parameters:\n        positive_samples (dict): Dictionary containing positive samples per bearing.\n        negative_samples (dict): Dictionary containing negative samples per bearing.\n        target_size (int): Total number of samples to randomly select.\n\n    Returns:\n        selected_positive (list): List of randomly chosen positive samples.\n        selected_negative (list): List of randomly chosen negative samples.\n    \"\"\"\n    # Flatten all samples into lists\n    all_positive = []\n    all_negative = []\n\n    for bearing in positive_samples.keys():\n        all_positive.extend(positive_samples[bearing])\n        all_negative.extend(negative_samples[bearing])\n\n    # Ensure equal selection from positive and negative datasets\n    selected_positive = random.sample(all_positive, target_size // 2)\n    selected_negative = random.sample(all_negative, target_size // 2)\n\n    return selected_positive, selected_negative\n\n# ğŸ”„ Select a limited number of pretext samples\nselected_positive, selected_negative = sample_pretext_data(positive_samples, negative_samples, TARGET_PRETEXT_SAMPLES)\n\n# Move selected data to GPU for faster training\nselected_positive = [sample.to(device) for sample in selected_positive]\nselected_negative = [sample.to(device) for sample in selected_negative]\n\n# Print dataset summary\nprint(\"\\nğŸ“Š Updated Pretext Training Dataset:\")\nprint(f\"âœ… Selected Positive Samples: {len(selected_positive)}\")\nprint(f\"âœ… Selected Negative Samples: {len(selected_negative)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T12:16:33.401574Z","iopub.execute_input":"2025-02-02T12:16:33.401857Z","iopub.status.idle":"2025-02-02T12:16:34.079899Z","shell.execute_reply.started":"2025-02-02T12:16:33.401836Z","shell.execute_reply":"2025-02-02T12:16:34.078975Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“Š Updated Pretext Training Dataset:\nâœ… Selected Positive Samples: 125760\nâœ… Selected Negative Samples: 125760\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# Detect and use GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸš€ Using device: {device}\")\n\nclass SiameseCNN(nn.Module):\n    def __init__(self):\n        super(SiameseCNN, self).__init__()\n\n        # Move CNN layers to GPU\n        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=3, padding=1).to(device)\n        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1).to(device)\n        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1).to(device)\n        \n        self.global_pool = nn.AdaptiveAvgPool1d(1).to(device)\n        \n        self.fc1 = nn.Linear(256, 128).to(device)\n        self.fc2 = nn.Linear(128, 64).to(device)\n\n    def forward(self, x):\n        x = x.to(device)  # Ensure input is on GPU\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.global_pool(x).squeeze(-1)  # Shape: (batch, 256)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)  # Output: (batch, 64)\n        return x\n\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, positive_features, negative_features):\n        distance = F.pairwise_distance(positive_features, negative_features)\n        loss = torch.mean(torch.pow(distance, 2))\n        return loss\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Define batch size\nbatch_size = 64\n\n# Convert selected data into TensorDataset and DataLoader\npositive_dataset = TensorDataset(torch.stack(selected_positive))\nnegative_dataset = TensorDataset(torch.stack(selected_negative))\n\npositive_loader = DataLoader(positive_dataset, batch_size=batch_size, shuffle=True)\nnegative_loader = DataLoader(negative_dataset, batch_size=batch_size, shuffle=True)\n\n# Initialize model and optimizer\ncnn_encoder = SiameseCNN().to(device)\ncontrastive_loss_fn = ContrastiveLoss().to(device)\noptimizer = optim.Adam(cnn_encoder.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    batch_count = 0\n\n    for (pos_batch, neg_batch) in zip(positive_loader, negative_loader):\n        pos_batch = pos_batch[0].to(device)  # Extract tensor from dataset and move to GPU\n        neg_batch = neg_batch[0].to(device)\n\n        # Forward pass\n        pos_features = cnn_encoder(pos_batch)\n        neg_features = cnn_encoder(neg_batch)\n\n        # Compute contrastive loss\n        loss = contrastive_loss_fn(pos_features, neg_features)\n        total_loss += loss.item()\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_count += 1\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {total_loss:.10f} | Processed {batch_count} batches.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T12:16:40.363932Z","iopub.execute_input":"2025-02-02T12:16:40.364290Z","iopub.status.idle":"2025-02-02T12:18:04.184648Z","shell.execute_reply.started":"2025-02-02T12:16:40.364252Z","shell.execute_reply":"2025-02-02T12:18:04.183803Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Using device: cuda\nEpoch [1/10] | Loss: 0.0053258782 | Processed 1965 batches.\nEpoch [2/10] | Loss: 0.0000157883 | Processed 1965 batches.\nEpoch [3/10] | Loss: 0.0000032113 | Processed 1965 batches.\nEpoch [4/10] | Loss: 0.0000007437 | Processed 1965 batches.\nEpoch [5/10] | Loss: 0.0000002920 | Processed 1965 batches.\nEpoch [6/10] | Loss: 0.0000002346 | Processed 1965 batches.\nEpoch [7/10] | Loss: 0.0000001529 | Processed 1965 batches.\nEpoch [8/10] | Loss: 0.0000001328 | Processed 1965 batches.\nEpoch [9/10] | Loss: 0.0000001263 | Processed 1965 batches.\nEpoch [10/10] | Loss: 0.0000001189 | Processed 1965 batches.\n","output_type":"stream"}],"execution_count":13}]}